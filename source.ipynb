{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "361d0d3c-b585-4027-8ddd-da5fe387595e",
   "metadata": {},
   "source": [
    "## Movie Review Sentiment Classification using N-Gram Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f94a6c00-5ac8-45dc-bb14-2ed9af2bdbb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Imalsha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Imalsha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "import nltk\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from nltk import ngrams\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893d6282-bfca-4a1d-8b35-fa9044a529e9",
   "metadata": {},
   "source": [
    "## Step 1: Import Movie Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7fda16e-56e8-49d0-8515-0a0bb1ce29c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie reviews imported successfully.\n"
     ]
    }
   ],
   "source": [
    "with open(\"Movie_Reviews.txt\", \"r\") as file:\n",
    "    movie_reviews = file.readlines()\n",
    "print(\"Movie reviews imported successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4a881c0-b6b1-4be0-9b05-22425673c554",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Positive Reviews\\n',\n",
       " '================\\n',\n",
       " '\\n',\n",
       " '1. \"Forrest Gump is an absolute masterpiece! Tom Hanks delivers an unforgettable performance, and the storytelling is heartwarming. This movie is a journey through life that will make you laugh, cry, and appreciate the simple beauties of existence.\"\\n',\n",
       " '\\n',\n",
       " '2. \"The Shawshank Redemption is a timeless classic. The powerful themes of hope, friendship, and redemption make it a must-watch. Morgan Freeman and Tim Robbins give exceptional performances in this brilliantly crafted film.\"\\n',\n",
       " '\\n',\n",
       " '3. \"The epic conclusion to The Lord of the Rings trilogy, The Return of the King, is a cinematic triumph. The breathtaking visuals, epic battles, and emotionally resonant story make it a monumental achievement in filmmaking.\"\\n',\n",
       " '\\n',\n",
       " '4. \"La La Land is a love letter to the magic of Hollywood and dreams. The chemistry between Ryan Gosling and Emma Stone is enchanting, and the music and dance sequences are a pure delight. A modern musical masterpiece.\"\\n',\n",
       " '\\n',\n",
       " '5. \"Wes Anderson\\'s whimsical style shines in The Grand Budapest Hotel. With its quirky characters and colorful cinematography, it\\'s a visual and narrative delight. This film is a charming and delightful experience.\"\\n',\n",
       " '\\n',\n",
       " '6.\"Inception is mind-bending brilliance! Christopher Nolan\\'s intricate plot, stunning visual effects, and Hans Zimmer\\'s haunting score create a cinematic journey that keeps you on the edge of your seat. A true masterpiece of sci-fi cinema.\"\\n',\n",
       " '\\n',\n",
       " '7. \"The Social Network is a captivating exploration of the creation of Facebook and the personal and legal conflicts that ensued. David Fincher\\'s direction and Aaron Sorkin\\'s sharp screenplay make this film a modern classic.\"\\n',\n",
       " '\\n',\n",
       " '8. \"Will Smith\\'s portrayal of Chris Gardner in The Pursuit of Happyness is both touching and inspirational. This film reminds us that with determination and unwavering spirit, anyone can overcome adversity to achieve their dreams.\"\\n',\n",
       " '\\n',\n",
       " '9. \"Eternal Sunshine of the Spotless Mind is a beautifully unconventional love story. Jim Carrey and Kate Winslet shine in their roles, and the narrative, told in a non-linear fashion, is a poignant exploration of love, memories, and human connection.\"\\n',\n",
       " '\\n',\n",
       " '10. \"The Princess Bride is a timeless fairy tale with a perfect blend of humor, romance, and adventure. Its witty dialogue and memorable characters make it a film that appeals to both kids and adults. Inconceivably delightful!\"\\n',\n",
       " '\\n',\n",
       " '11. \"Fifty Shades of Grey\" has managed to captivate both enthusiasts and critics alike. The film\\'s ability to spark passionate discussions and elicit a wide range of opinions is a testament to its impact. While some may find it controversial, there\\'s no denying that it has left a significant mark on the world of cinema.\\n',\n",
       " '\\n',\n",
       " '12. \"This film has been a conversation starter, and it\\'s clear that it won\\'t be everyone\\'s cup of tea. But for those willing to approach it with an open mind, there\\'s a visually lush experience with moments of genuine chemistry between the leads. It\\'s a film that has managed to offer something different and intriguing in the world of romance and drama.\"\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " 'Negative Reviews\\n',\n",
       " '================\\n',\n",
       " '1. \"The Last Airbender is a disaster of a film adaptation. It butchers the beloved animated series with wooden acting, convoluted storytelling, and cringe-worthy special effects. A letdown for fans and newcomers alike.\"\\n',\n",
       " '\\n',\n",
       " '2. \"Another Transformers movie, and it\\'s just more of the same: mindless explosions, incoherent plotlines, and an overreliance on CGI. This franchise desperately needs an overhaul.\"\\n',\n",
       " '\\n',\n",
       " '3. \"The Emoji Movie is a blatant cash grab with a shallow, uninspired plot. It fails to deliver clever humor or meaningful messages, making it a forgettable and disappointing animated film.\"\\n',\n",
       " '\\n',\n",
       " '4. \"Fifty Shades of Grey is a cringe-inducing attempt at romance. Poorly written dialogue and unconvincing chemistry between the leads make it an awkward and unfulfilling cinematic experience.\"\\n',\n",
       " '\\n',\n",
       " '5. \"Jack and Jill is an unbearable comedy that relies on stale humor and a painfully unfunny portrayal of Adam Sandler in a dual role. It\\'s a prime example of lazy filmmaking.\"\\n',\n",
       " '\\n',\n",
       " '6. \"Superman IV is a colossal disappointment. It\\'s marred by a low budget, laughable special effects, and a poorly conceived story. Even Christopher Reeve\\'s charm can\\'t save this mess.\"\\n',\n",
       " '\\n',\n",
       " '7. \"The Cat in the Hat is a chaotic and misguided adaptation of Dr. Seuss\\'s classic. It sacrifices the charm and simplicity of the source material for crude humor and a lackluster narrative.\"\\n',\n",
       " '\\n',\n",
       " '8. \"The Room is widely regarded as one of the worst films ever made. Its disjointed plot, stilted acting, and bizarre dialogue have turned it into a cult classic, but not for the right reasons.\"\\n',\n",
       " '\\n',\n",
       " '9. \"Battlefield Earth is a sci-fi disaster. It\\'s a convoluted mess with hammy acting and laughable special effects. A film that should have remained buried in the annals of cinematic history.\"\\n',\n",
       " '\\n',\n",
       " '10. \"Gigli is a train wreck of a romantic comedy. The pairing of Ben Affleck and Jennifer Lopez is devoid of chemistry, and the dialogue is cringeworthy. It\\'s an embarrassing misstep in both their careers.\"\\n',\n",
       " '\\n',\n",
       " '11. \"Fifty Shades of Grey\" is a film that has divided enthusiasts and critics. While it has its share of devoted fans, it also faces substantial criticism. For some, the film\\'s content and execution leave much to be desired, making it a polarizing cinematic experience. Viewer reactions may vary widely, so it\\'s a movie that evokes strong opinions on both ends of the spectrum.\\n',\n",
       " '\\n',\n",
       " '12. \"This film\\'s portrayal of relationships and themes may leave many viewers uncomfortable. It tests the limits of what some may find acceptable in mainstream cinema. So, while the idea of keeping an open mind is essential in film-watching, this particular movie might push that openness to its boundaries for some.\"\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '=====================================================================\\n',\n",
       " '\\n',\n",
       " \"It's clear that the movie has both its enthusiasts and critics. While it may not be to everyone's taste, it's worth watching with an open mind to form your own opinion. \\n\"]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6de9df-8453-4e50-aff6-59e9d8c4da1b",
   "metadata": {},
   "source": [
    "* The following code aims to split the list of movie reviews into positive and negative arrays. It defines the function 'split_reviews' that takes a list of reviews as input and separates them based on the markers 'Positive Reviews\\n' and 'Negative Reviews\\n'. \n",
    "* The resulting positive and negative arrays are then printed along with a 'test_array' containing the last element of the original movie_reviews list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a08da18f-b96b-478c-9d60-d790a62a2dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['================\\n', '\\n', '1. \"Forrest Gump is an absolute masterpiece! Tom Hanks delivers an unforgettable performance, and the storytelling is heartwarming. This movie is a journey through life that will make you laugh, cry, and appreciate the simple beauties of existence.\"\\n', '\\n', '2. \"The Shawshank Redemption is a timeless classic. The powerful themes of hope, friendship, and redemption make it a must-watch. Morgan Freeman and Tim Robbins give exceptional performances in this brilliantly crafted film.\"\\n', '\\n', '3. \"The epic conclusion to The Lord of the Rings trilogy, The Return of the King, is a cinematic triumph. The breathtaking visuals, epic battles, and emotionally resonant story make it a monumental achievement in filmmaking.\"\\n', '\\n', '4. \"La La Land is a love letter to the magic of Hollywood and dreams. The chemistry between Ryan Gosling and Emma Stone is enchanting, and the music and dance sequences are a pure delight. A modern musical masterpiece.\"\\n', '\\n', '5. \"Wes Anderson\\'s whimsical style shines in The Grand Budapest Hotel. With its quirky characters and colorful cinematography, it\\'s a visual and narrative delight. This film is a charming and delightful experience.\"\\n', '\\n', '6.\"Inception is mind-bending brilliance! Christopher Nolan\\'s intricate plot, stunning visual effects, and Hans Zimmer\\'s haunting score create a cinematic journey that keeps you on the edge of your seat. A true masterpiece of sci-fi cinema.\"\\n', '\\n', '7. \"The Social Network is a captivating exploration of the creation of Facebook and the personal and legal conflicts that ensued. David Fincher\\'s direction and Aaron Sorkin\\'s sharp screenplay make this film a modern classic.\"\\n', '\\n', '8. \"Will Smith\\'s portrayal of Chris Gardner in The Pursuit of Happyness is both touching and inspirational. This film reminds us that with determination and unwavering spirit, anyone can overcome adversity to achieve their dreams.\"\\n', '\\n', '9. \"Eternal Sunshine of the Spotless Mind is a beautifully unconventional love story. Jim Carrey and Kate Winslet shine in their roles, and the narrative, told in a non-linear fashion, is a poignant exploration of love, memories, and human connection.\"\\n', '\\n', '10. \"The Princess Bride is a timeless fairy tale with a perfect blend of humor, romance, and adventure. Its witty dialogue and memorable characters make it a film that appeals to both kids and adults. Inconceivably delightful!\"\\n', '\\n', '11. \"Fifty Shades of Grey\" has managed to captivate both enthusiasts and critics alike. The film\\'s ability to spark passionate discussions and elicit a wide range of opinions is a testament to its impact. While some may find it controversial, there\\'s no denying that it has left a significant mark on the world of cinema.\\n', '\\n', '12. \"This film has been a conversation starter, and it\\'s clear that it won\\'t be everyone\\'s cup of tea. But for those willing to approach it with an open mind, there\\'s a visually lush experience with moments of genuine chemistry between the leads. It\\'s a film that has managed to offer something different and intriguing in the world of romance and drama.\"\\n', '\\n', '\\n']\n",
      "['================\\n', '1. \"The Last Airbender is a disaster of a film adaptation. It butchers the beloved animated series with wooden acting, convoluted storytelling, and cringe-worthy special effects. A letdown for fans and newcomers alike.\"\\n', '\\n', '2. \"Another Transformers movie, and it\\'s just more of the same: mindless explosions, incoherent plotlines, and an overreliance on CGI. This franchise desperately needs an overhaul.\"\\n', '\\n', '3. \"The Emoji Movie is a blatant cash grab with a shallow, uninspired plot. It fails to deliver clever humor or meaningful messages, making it a forgettable and disappointing animated film.\"\\n', '\\n', '4. \"Fifty Shades of Grey is a cringe-inducing attempt at romance. Poorly written dialogue and unconvincing chemistry between the leads make it an awkward and unfulfilling cinematic experience.\"\\n', '\\n', '5. \"Jack and Jill is an unbearable comedy that relies on stale humor and a painfully unfunny portrayal of Adam Sandler in a dual role. It\\'s a prime example of lazy filmmaking.\"\\n', '\\n', '6. \"Superman IV is a colossal disappointment. It\\'s marred by a low budget, laughable special effects, and a poorly conceived story. Even Christopher Reeve\\'s charm can\\'t save this mess.\"\\n', '\\n', '7. \"The Cat in the Hat is a chaotic and misguided adaptation of Dr. Seuss\\'s classic. It sacrifices the charm and simplicity of the source material for crude humor and a lackluster narrative.\"\\n', '\\n', '8. \"The Room is widely regarded as one of the worst films ever made. Its disjointed plot, stilted acting, and bizarre dialogue have turned it into a cult classic, but not for the right reasons.\"\\n', '\\n', '9. \"Battlefield Earth is a sci-fi disaster. It\\'s a convoluted mess with hammy acting and laughable special effects. A film that should have remained buried in the annals of cinematic history.\"\\n', '\\n', '10. \"Gigli is a train wreck of a romantic comedy. The pairing of Ben Affleck and Jennifer Lopez is devoid of chemistry, and the dialogue is cringeworthy. It\\'s an embarrassing misstep in both their careers.\"\\n', '\\n', '11. \"Fifty Shades of Grey\" is a film that has divided enthusiasts and critics. While it has its share of devoted fans, it also faces substantial criticism. For some, the film\\'s content and execution leave much to be desired, making it a polarizing cinematic experience. Viewer reactions may vary widely, so it\\'s a movie that evokes strong opinions on both ends of the spectrum.\\n', '\\n', '12. \"This film\\'s portrayal of relationships and themes may leave many viewers uncomfortable. It tests the limits of what some may find acceptable in mainstream cinema. So, while the idea of keeping an open mind is essential in film-watching, this particular movie might push that openness to its boundaries for some.\"\\n', '\\n', '\\n', '\\n', '=====================================================================\\n', '\\n']\n",
      "[\"It's clear that the movie has both its enthusiasts and critics. While it may not be to everyone's taste, it's worth watching with an open mind to form your own opinion. \\n\"]\n"
     ]
    }
   ],
   "source": [
    "test_array = [movie_reviews[-1]]\n",
    "\n",
    "def split_reviews(reviews):\n",
    "    \n",
    "    pos_array = []\n",
    "    neg_array = []\n",
    "    \n",
    "    pos_index = reviews.index(\"Positive Reviews\\n\")\n",
    "    neg_index = reviews.index(\"Negative Reviews\\n\")\n",
    "    \n",
    "    pos_array += reviews[pos_index+1: neg_index]\n",
    "    neg_array += reviews[neg_index+1:]\n",
    "    \n",
    "    return pos_array, neg_array\n",
    "\n",
    "movie_reviews.pop()\n",
    "pos_array, neg_array = split_reviews(movie_reviews)\n",
    "\n",
    "print(pos_array)\n",
    "print(neg_array)\n",
    "print(test_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c3386a7-7b69-40cb-ab9b-7565ba374826",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_df = pd.DataFrame({\"review\": pos_array})\n",
    "neg_df = pd.DataFrame({\"review\": neg_array})\n",
    "test_df = pd.DataFrame({\"review\": test_array})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9fbfdbc5-9cc1-4b80-a364-7ab8f145cf54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                                               review\n",
       " 0                                  ================\\n\n",
       " 1                                                  \\n\n",
       " 2   1. \"Forrest Gump is an absolute masterpiece! T...\n",
       " 3                                                  \\n\n",
       " 4   2. \"The Shawshank Redemption is a timeless cla...\n",
       " 5                                                  \\n\n",
       " 6   3. \"The epic conclusion to The Lord of the Rin...\n",
       " 7                                                  \\n\n",
       " 8   4. \"La La Land is a love letter to the magic o...\n",
       " 9                                                  \\n\n",
       " 10  5. \"Wes Anderson's whimsical style shines in T...\n",
       " 11                                                 \\n\n",
       " 12  6.\"Inception is mind-bending brilliance! Chris...\n",
       " 13                                                 \\n\n",
       " 14  7. \"The Social Network is a captivating explor...\n",
       " 15                                                 \\n\n",
       " 16  8. \"Will Smith's portrayal of Chris Gardner in...\n",
       " 17                                                 \\n\n",
       " 18  9. \"Eternal Sunshine of the Spotless Mind is a...\n",
       " 19                                                 \\n\n",
       " 20  10. \"The Princess Bride is a timeless fairy ta...\n",
       " 21                                                 \\n\n",
       " 22  11. \"Fifty Shades of Grey\" has managed to capt...\n",
       " 23                                                 \\n\n",
       " 24  12. \"This film has been a conversation starter...\n",
       " 25                                                 \\n\n",
       " 26                                                 \\n,\n",
       "                                                review\n",
       " 0                                  ================\\n\n",
       " 1   1. \"The Last Airbender is a disaster of a film...\n",
       " 2                                                  \\n\n",
       " 3   2. \"Another Transformers movie, and it's just ...\n",
       " 4                                                  \\n\n",
       " 5   3. \"The Emoji Movie is a blatant cash grab wit...\n",
       " 6                                                  \\n\n",
       " 7   4. \"Fifty Shades of Grey is a cringe-inducing ...\n",
       " 8                                                  \\n\n",
       " 9   5. \"Jack and Jill is an unbearable comedy that...\n",
       " 10                                                 \\n\n",
       " 11  6. \"Superman IV is a colossal disappointment. ...\n",
       " 12                                                 \\n\n",
       " 13  7. \"The Cat in the Hat is a chaotic and misgui...\n",
       " 14                                                 \\n\n",
       " 15  8. \"The Room is widely regarded as one of the ...\n",
       " 16                                                 \\n\n",
       " 17  9. \"Battlefield Earth is a sci-fi disaster. It...\n",
       " 18                                                 \\n\n",
       " 19  10. \"Gigli is a train wreck of a romantic come...\n",
       " 20                                                 \\n\n",
       " 21  11. \"Fifty Shades of Grey\" is a film that has ...\n",
       " 22                                                 \\n\n",
       " 23  12. \"This film's portrayal of relationships an...\n",
       " 24                                                 \\n\n",
       " 25                                                 \\n\n",
       " 26                                                 \\n\n",
       " 27  ==============================================...\n",
       " 28                                                 \\n,\n",
       "                                               review\n",
       " 0  It's clear that the movie has both its enthusi...)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_df, neg_df, test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48c702f-1112-47e1-b8f9-0e1d5a0eb085",
   "metadata": {},
   "source": [
    "## Step 2: Pre-process the Text Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4518220-8712-4f25-95e2-bae3d7ce2961",
   "metadata": {},
   "source": [
    "##### Text Preprocessing Class\n",
    "###### ----------------------------------\n",
    "\n",
    "* The following class, **TextPreprocessing**, defines a set of methods for common text preprocessing tasks.\n",
    "* It includes functions for removing punctuation, unwanted characters, numeric digits, converting to lowercase, tokenizing, and removing English stopwords.\n",
    "* Additionally, it provides a pipeline method that applies a series of these preprocessing steps to a DataFrame column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "660ca301-07a6-45e7-9396-4bab67187da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextPreprocessing:\n",
    "    \n",
    "    def __init__(self, stopwords_list_english):\n",
    "        self.stopwords_list_english=stopwords_list_english\n",
    "    \n",
    "    def removePunc(self, text):\n",
    "        punctuationfree = \"\".join([i for i in text if i not in string.punctuation])\n",
    "        return punctuationfree\n",
    "    \n",
    "    def removeUnwanted(self, text):\n",
    "        text = re.sub('\\n ','',text)\n",
    "        text = re.sub('\\n','',text)\n",
    "        text = re.sub(r\"^\\s+\",\"\",text)\n",
    "        text = re.sub(r\"\\s+\",\" \",text)\n",
    "        text = re.sub(r\"\\u200d\",\"\",text)\n",
    "        text = re.sub(r\"\\u200c\",\"\",text)\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    def removeNum(self, text):\n",
    "        remove_digits = str.maketrans('', '', string.digits)\n",
    "        return text.translate(remove_digits)\n",
    "    \n",
    "    def lowerCase(self, text):\n",
    "        return text.lower()\n",
    "    \n",
    "    def tokenize(self, text):\n",
    "        return word_tokenize(text)\n",
    "        \n",
    "    def removeStopwordsEnglish(self, text):\n",
    "        output= [i for i in text if i not in self.stopwords_list_english]\n",
    "        return output\n",
    "    \n",
    "    def pipeline(self, df, column_name):\n",
    "        \n",
    "        df_temp = df.copy()\n",
    "        df_temp[column_name] = df_temp[column_name].apply(lambda x: self.removePunc(x))\n",
    "        df_temp[column_name] = df_temp[column_name].apply(lambda x: self.removeNum(x))\n",
    "        df_temp[column_name] = df_temp[column_name].apply(lambda x: self.removeUnwanted(x))\n",
    "        \n",
    "        df_temp = df_temp[df_temp[column_name].astype(bool)].reset_index(drop=True)\n",
    "        \n",
    "        df_temp[column_name] = df_temp[column_name].apply(lambda x: self.lowerCase(x))\n",
    "        df_temp[column_name] = df_temp[column_name].apply(lambda x: self.tokenize(x))\n",
    "        df_temp[column_name] = df_temp[column_name].apply(lambda x: self.removeStopwordsEnglish(x))\n",
    "                \n",
    "        return df_temp\n",
    "    \n",
    "preprocessing = TextPreprocessing(\n",
    "    stopwords_list_english=stopwords.words('english')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d728794-5e6a-4c3c-b70e-6589fb1ac5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_df = preprocessing.pipeline(pos_df, \"review\")\n",
    "neg_df = preprocessing.pipeline(neg_df, \"review\")\n",
    "test_df = preprocessing.pipeline(test_df, \"review\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a617233c-ff2a-4697-a801-a82d047498af",
   "metadata": {},
   "source": [
    "## Step 3: Choose N and Implement N-Gram Model (e.g., Unigram, Bigram)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce4631e-77fd-4943-b9cd-a2420706e32d",
   "metadata": {},
   "source": [
    "#### Using the Unigram Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828cc40a-b611-4e07-804f-0ba6f2a82321",
   "metadata": {},
   "source": [
    "The given dataset can be identified as a relatively small dataset with a limited number of reviews. Therefore, For a small dataset with distributed values, choosing a unigram model (N=1) can be a reasonable and practical choice. Unigrams consider each word in isolation, making them computationally less demanding and suitable for datasets where capturing complex dependencies between words may be challenging due to limited data.\n",
    "\n",
    "When using higher-order models like Trigrams (N=3) or higher, we consider more context, which can capture richer dependencies between words. However, with a small dataset, higher-order models may suffer from the \"sparsity problem.\" This problem arises because the model needs to estimate probabilities for all possible combinations of N-grams, and some of these combinations may not appear in the limited data.\n",
    "F for a small dataset with distributed values, starting with a Unigram model is a sensible choice due to its simplicity and the ability to handle sparsity issues. \n",
    "\n",
    "Therefore decided to I cohose **Unigram Model** in this scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8f37b11-9941-4c23-a3ff-021961992259",
   "metadata": {},
   "outputs": [],
   "source": [
    "#N-gram number\n",
    "n = 1\n",
    "\n",
    "# Function to tokenize and generate N-grams\n",
    "def generate_ngrams(text):\n",
    "    ngrams_list = list(zip(*[text[i:] for i in range(n)]))\n",
    "    return ngrams_list\n",
    "\n",
    "def process_datasets(df):\n",
    "    \n",
    "    temp_df = df.copy()\n",
    "    \n",
    "    # Create a new column with N-grams\n",
    "    temp_df['ngrams'] = temp_df['review'].apply(generate_ngrams)\n",
    "\n",
    "    # Flatten the N-grams lists and count their occurrences\n",
    "    all_ngrams = [item for sublist in temp_df['ngrams'] for item in sublist]\n",
    "    ngram_counts = Counter(all_ngrams)\n",
    "    total_ngrams = sum(ngram_counts.values())\n",
    "\n",
    "    # Convert the N-gram frequencies to a DataFrame\n",
    "    ngram_df = pd.DataFrame(list(ngram_counts.items()), columns=['ngram', 'frequency']).sort_values(by='frequency', ascending=False)\n",
    "    \n",
    "    return ngram_df, total_ngrams\n",
    "\n",
    "ngram_pos, total_pos = process_datasets(pos_df)\n",
    "ngram_neg, total_neg = process_datasets(neg_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62aa2dec-0b6b-42be-9bb1-0b5d1badd36a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ngram</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>(film,)</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(make,)</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>(love,)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(masterpiece,)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>(romance,)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>(charming,)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>(inception,)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>(mindbending,)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>(brilliance,)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>(drama,)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>232 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              ngram  frequency\n",
       "39          (film,)          7\n",
       "14          (make,)          5\n",
       "60          (love,)          3\n",
       "3    (masterpiece,)          3\n",
       "175      (romance,)          2\n",
       "..              ...        ...\n",
       "92      (charming,)          1\n",
       "95     (inception,)          1\n",
       "96   (mindbending,)          1\n",
       "97    (brilliance,)          1\n",
       "231        (drama,)          1\n",
       "\n",
       "[232 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1b5629fb-6373-4017-a692-fb43eca2c49a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ngram</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>(movie,)</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(film,)</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>(cinematic,)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>(may,)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>(dialogue,)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>(lazy,)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>(filmmaking,)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>(superman,)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>(iv,)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>(boundaries,)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>196 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ngram  frequency\n",
       "22        (movie,)          4\n",
       "3          (film,)          4\n",
       "64    (cinematic,)          3\n",
       "167         (may,)          3\n",
       "57     (dialogue,)          3\n",
       "..             ...        ...\n",
       "81         (lazy,)          1\n",
       "82   (filmmaking,)          1\n",
       "83     (superman,)          1\n",
       "84           (iv,)          1\n",
       "195  (boundaries,)          1\n",
       "\n",
       "[196 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram_neg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d567839c-81ac-4df6-95cd-6e65b0f4be3e",
   "metadata": {},
   "source": [
    "## Step 4: Calculate the N-gram probabilities for each N-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a83a1596-b773-4abe-88a9-9aa05801f438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N-gram: ('film',) ----- Frequency: 7 ----- Probability: 0.025925925925925925\n",
      "N-gram: ('make',) ----- Frequency: 5 ----- Probability: 0.018518518518518517\n",
      "N-gram: ('love',) ----- Frequency: 3 ----- Probability: 0.011111111111111112\n",
      "N-gram: ('masterpiece',) ----- Frequency: 3 ----- Probability: 0.011111111111111112\n",
      "N-gram: ('romance',) ----- Frequency: 2 ----- Probability: 0.007407407407407408\n",
      "N-gram: ('world',) ----- Frequency: 2 ----- Probability: 0.007407407407407408\n",
      "N-gram: ('timeless',) ----- Frequency: 2 ----- Probability: 0.007407407407407408\n",
      "N-gram: ('classic',) ----- Frequency: 2 ----- Probability: 0.007407407407407408\n",
      "N-gram: ('managed',) ----- Frequency: 2 ----- Probability: 0.007407407407407408\n",
      "N-gram: ('story',) ----- Frequency: 2 ----- Probability: 0.007407407407407408\n",
      "N-gram: ('theres',) ----- Frequency: 2 ----- Probability: 0.007407407407407408\n",
      "N-gram: ('characters',) ----- Frequency: 2 ----- Probability: 0.007407407407407408\n",
      "N-gram: ('experience',) ----- Frequency: 2 ----- Probability: 0.007407407407407408\n",
      "N-gram: ('mind',) ----- Frequency: 2 ----- Probability: 0.007407407407407408\n",
      "N-gram: ('visual',) ----- Frequency: 2 ----- Probability: 0.007407407407407408\n",
      "N-gram: ('cinematic',) ----- Frequency: 2 ----- Probability: 0.007407407407407408\n",
      "N-gram: ('narrative',) ----- Frequency: 2 ----- Probability: 0.007407407407407408\n",
      "N-gram: ('epic',) ----- Frequency: 2 ----- Probability: 0.007407407407407408\n",
      "N-gram: ('redemption',) ----- Frequency: 2 ----- Probability: 0.007407407407407408\n",
      "N-gram: ('delightful',) ----- Frequency: 2 ----- Probability: 0.007407407407407408\n",
      "N-gram: ('chemistry',) ----- Frequency: 2 ----- Probability: 0.007407407407407408\n",
      "N-gram: ('cinema',) ----- Frequency: 2 ----- Probability: 0.007407407407407408\n",
      "N-gram: ('delight',) ----- Frequency: 2 ----- Probability: 0.007407407407407408\n",
      "N-gram: ('journey',) ----- Frequency: 2 ----- Probability: 0.007407407407407408\n",
      "N-gram: ('modern',) ----- Frequency: 2 ----- Probability: 0.007407407407407408\n",
      "N-gram: ('exploration',) ----- Frequency: 2 ----- Probability: 0.007407407407407408\n",
      "N-gram: ('la',) ----- Frequency: 2 ----- Probability: 0.007407407407407408\n",
      "N-gram: ('dreams',) ----- Frequency: 2 ----- Probability: 0.007407407407407408\n",
      "N-gram: ('memories',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('perfect',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('shine',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('tale',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('fairy',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('told',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('roles',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('nonlinear',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('fashion',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('bride',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('princess',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('connection',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('human',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('poignant',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('forrest',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('winslet',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('determination',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('sharp',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('screenplay',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('smiths',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('portrayal',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('chris',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('gardner',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('pursuit',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('happyness',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('touching',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('inspirational',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('reminds',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('us',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('unwavering',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('kate',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('spirit',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('anyone',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('overcome',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('adversity',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('achieve',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('eternal',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('sunshine',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('spotless',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('beautifully',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('blend',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('jim',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('carrey',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('unconventional',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('kids',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('humor',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('tea',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('controversial',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('denying',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('left',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('significant',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('mark',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('conversation',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('starter',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('clear',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('wont',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('everyones',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('cup',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('willing',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('adventure',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('approach',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('open',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('visually',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('lush',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('moments',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('genuine',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('leads',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('offer',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('something',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('different',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('intriguing',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('find',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('may',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('impact',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('testament',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('witty',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('dialogue',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('memorable',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('appeals',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('aaron',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('adults',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('inconceivably',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('fifty',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('shades',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('grey',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('captivate',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('enthusiasts',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('critics',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('alike',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('films',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('ability',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('spark',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('passionate',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('discussions',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('elicit',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('wide',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('range',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('opinions',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('sorkins',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('network',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('direction',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('finchers',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('give',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('exceptional',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('performances',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('brilliantly',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('crafted',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('conclusion',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('lord',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('rings',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('trilogy',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('return',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('king',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('triumph',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('breathtaking',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('visuals',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('battles',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('emotionally',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('resonant',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('monumental',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('achievement',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('filmmaking',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('land',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('letter',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('magic',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('robbins',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('tim',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('freeman',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('laugh',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('absolute',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('tom',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('hanks',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('delivers',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('unforgettable',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('performance',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('storytelling',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('heartwarming',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('movie',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('life',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('cry',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('morgan',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('appreciate',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('simple',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('beauties',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('existence',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('shawshank',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('powerful',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('themes',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('hope',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('friendship',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('mustwatch',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('hollywood',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('ryan',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('gosling',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('true',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('stunning',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('effects',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('hans',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('zimmers',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('haunting',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('score',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('create',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('keeps',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('edge',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('seat',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('scifi',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('intricate',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('social',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('gump',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('captivating',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('creation',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('facebook',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('personal',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('legal',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('conflicts',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('ensued',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('david',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('plot',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('nolans',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('emma',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('style',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('stone',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('enchanting',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('music',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('dance',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('sequences',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('pure',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('musical',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('wes',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('andersons',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('whimsical',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('shines',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('christopher',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('grand',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('budapest',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('hotel',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('quirky',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('colorful',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('cinematography',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('charming',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('inception',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('mindbending',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('brilliance',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "N-gram: ('drama',) ----- Frequency: 1 ----- Probability: 0.003703703703703704\n",
      "==========================================\n",
      "N-gram: ('movie',) ----- Frequency: 4 ----- Probability: 0.016666666666666666\n",
      "N-gram: ('film',) ----- Frequency: 4 ----- Probability: 0.016666666666666666\n",
      "N-gram: ('cinematic',) ----- Frequency: 3 ----- Probability: 0.0125\n",
      "N-gram: ('may',) ----- Frequency: 3 ----- Probability: 0.0125\n",
      "N-gram: ('dialogue',) ----- Frequency: 3 ----- Probability: 0.0125\n",
      "N-gram: ('films',) ----- Frequency: 3 ----- Probability: 0.0125\n",
      "N-gram: ('effects',) ----- Frequency: 3 ----- Probability: 0.0125\n",
      "N-gram: ('special',) ----- Frequency: 3 ----- Probability: 0.0125\n",
      "N-gram: ('acting',) ----- Frequency: 3 ----- Probability: 0.0125\n",
      "N-gram: ('humor',) ----- Frequency: 3 ----- Probability: 0.0125\n",
      "N-gram: ('experience',) ----- Frequency: 2 ----- Probability: 0.008333333333333333\n",
      "N-gram: ('mess',) ----- Frequency: 2 ----- Probability: 0.008333333333333333\n",
      "N-gram: ('disaster',) ----- Frequency: 2 ----- Probability: 0.008333333333333333\n",
      "N-gram: ('making',) ----- Frequency: 2 ----- Probability: 0.008333333333333333\n",
      "N-gram: ('plot',) ----- Frequency: 2 ----- Probability: 0.008333333333333333\n",
      "N-gram: ('fifty',) ----- Frequency: 2 ----- Probability: 0.008333333333333333\n",
      "N-gram: ('shades',) ----- Frequency: 2 ----- Probability: 0.008333333333333333\n",
      "N-gram: ('grey',) ----- Frequency: 2 ----- Probability: 0.008333333333333333\n",
      "N-gram: ('laughable',) ----- Frequency: 2 ----- Probability: 0.008333333333333333\n",
      "N-gram: ('leave',) ----- Frequency: 2 ----- Probability: 0.008333333333333333\n",
      "N-gram: ('poorly',) ----- Frequency: 2 ----- Probability: 0.008333333333333333\n",
      "N-gram: ('convoluted',) ----- Frequency: 2 ----- Probability: 0.008333333333333333\n",
      "N-gram: ('adaptation',) ----- Frequency: 2 ----- Probability: 0.008333333333333333\n",
      "N-gram: ('charm',) ----- Frequency: 2 ----- Probability: 0.008333333333333333\n",
      "N-gram: ('chemistry',) ----- Frequency: 2 ----- Probability: 0.008333333333333333\n",
      "N-gram: ('widely',) ----- Frequency: 2 ----- Probability: 0.008333333333333333\n",
      "N-gram: ('classic',) ----- Frequency: 2 ----- Probability: 0.008333333333333333\n",
      "N-gram: ('cringeworthy',) ----- Frequency: 2 ----- Probability: 0.008333333333333333\n",
      "N-gram: ('animated',) ----- Frequency: 2 ----- Probability: 0.008333333333333333\n",
      "N-gram: ('fans',) ----- Frequency: 2 ----- Probability: 0.008333333333333333\n",
      "N-gram: ('portrayal',) ----- Frequency: 2 ----- Probability: 0.008333333333333333\n",
      "N-gram: ('comedy',) ----- Frequency: 2 ----- Probability: 0.008333333333333333\n",
      "N-gram: ('affleck',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('ben',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('embarrassing',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('careers',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('lopez',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('misstep',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('devoid',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('pairing',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('romantic',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('jennifer',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('train',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('wreck',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('last',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('gigli',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('turned',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('room',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('regarded',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('one',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('worst',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('ever',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('made',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('disjointed',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('stilted',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('bizarre',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('cult',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('history',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('right',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('reasons',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('battlefield',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('earth',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('divided',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('hammy',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('remained',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('buried',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('annals',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('scifi',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('criticism',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('enthusiasts',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('idea',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('viewers',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('uncomfortable',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('tests',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('limits',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('find',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('acceptable',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('mainstream',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('cinema',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('keeping',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('themes',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('open',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('mind',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('essential',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('filmwatching',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('particular',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('might',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('push',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('openness',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('many',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('relationships',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('critics',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('much',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('share',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('devoted',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('also',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('faces',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('substantial',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('lackluster',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('content',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('execution',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('desired',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('spectrum',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('polarizing',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('viewer',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('reactions',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('vary',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('evokes',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('strong',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('opinions',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('ends',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('narrative',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('save',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('crude',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('overhaul',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('blatant',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('cash',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('grab',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('shallow',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('uninspired',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('fails',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('deliver',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('clever',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('meaningful',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('messages',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('forgettable',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('disappointing',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('cringeinducing',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('attempt',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('romance',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('written',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('unconvincing',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('emoji',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('needs',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('make',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('desperately',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('butchers',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('beloved',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('series',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('wooden',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('storytelling',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('letdown',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('newcomers',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('alike',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('another',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('transformers',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('mindless',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('explosions',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('incoherent',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('plotlines',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('overreliance',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('cgi',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('franchise',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('leads',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('awkward',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('material',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('marred',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('budget',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('conceived',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('story',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('even',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('christopher',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('reeves',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('cant',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('airbender',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('cat',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('hat',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('chaotic',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('misguided',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('dr',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('seusss',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('sacrifices',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('simplicity',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('source',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('low',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('disappointment',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('unfulfilling',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('colossal',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('jack',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('jill',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('unbearable',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('relies',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('stale',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('painfully',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('unfunny',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('adam',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('sandler',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('dual',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('role',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('prime',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('example',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('lazy',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('filmmaking',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('superman',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('iv',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "N-gram: ('boundaries',) ----- Frequency: 1 ----- Probability: 0.004166666666666667\n",
      "==========================================\n"
     ]
    }
   ],
   "source": [
    "def calculate_ngram_probabilities(df, total):\n",
    "    df_records = df.to_dict('records')\n",
    "    \n",
    "    for i in df_records:\n",
    "        print(\"N-gram: {} ----- Frequency: {} ----- Probability: {}\".format(i['ngram'], i['frequency'], i['frequency']/total))\n",
    "    \n",
    "    print(\"==========================================\")\n",
    "    \n",
    "calculate_ngram_probabilities(ngram_pos, total_pos)\n",
    "calculate_ngram_probabilities(ngram_neg, total_neg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d53e7e4-48b0-405d-8cb6-775aab7462e5",
   "metadata": {},
   "source": [
    "## Step 5: Calculate N-Gram Probability for Test Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc1ecfc0-a4ab-4631-903f-e39cea139e47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['clear',\n",
       " 'movie',\n",
       " 'enthusiasts',\n",
       " 'critics',\n",
       " 'may',\n",
       " 'everyones',\n",
       " 'taste',\n",
       " 'worth',\n",
       " 'watching',\n",
       " 'open',\n",
       " 'mind',\n",
       " 'form',\n",
       " 'opinion']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = test_df['review'][0]\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "54316ac4-9f7c-4b3c-b777-4d4f14e93624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of the sentence with respect to the positive dataset:  7.081412322944303e-20\n",
      "Probability of the sentence with respect to the negative dataset: 6.279337062757202e-14\n"
     ]
    }
   ],
   "source": [
    "def calculate_sentence_probability(tokens, ngram_df, total):\n",
    "    \n",
    "    df_records = dict(ngram_df.values)\n",
    "    test_ngrams = generate_ngrams(tokens)\n",
    "    \n",
    "    # Calculate the probability of the sentence using ngram probabilities\n",
    "    sentence_probability = 1.0  # Initialize the probability to 1.0\n",
    "\n",
    "    for ngram in test_ngrams:\n",
    "        if ngram in df_records:\n",
    "            sentence_probability = sentence_probability * (df_records[ngram]/total)\n",
    "\n",
    "    return sentence_probability\n",
    "    \n",
    "pos_prob = calculate_sentence_probability(tokens, ngram_pos, total_pos)\n",
    "neg_prob = calculate_sentence_probability(tokens, ngram_neg, total_neg)\n",
    "\n",
    "print(\"Probability of the sentence with respect to the positive dataset: \", pos_prob)\n",
    "print(\"Probability of the sentence with respect to the negative dataset:\", neg_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362a1c03-e971-4e84-ab6b-0065854ae5ac",
   "metadata": {},
   "source": [
    "## Step 6: Predict the category of the test movie review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c4c5beda-f0e2-4403-aa2e-6312305c4076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative Sentiment\n"
     ]
    }
   ],
   "source": [
    "if pos_prob > neg_prob:\n",
    "    print(\"Positive Sentiment\")\n",
    "elif pos_prob < neg_prob:\n",
    "    print(\"Negative Sentiment\")\n",
    "else:\n",
    "    print(\"Neutral Sentiment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77eb366f-62b6-41d3-9295-d74f91536f50",
   "metadata": {},
   "source": [
    "The probability of belonging to the positive reviews dataset is approximately 7.08e-20, and the probability of belonging to the negative reviews dataset is approximately 6.28e-14. These values suggest that the test movie review is more likely associated with the negative reviews dataset, as the probability for negativity is significantly higher than that for positivity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd69791-b474-402e-9544-3abadc099010",
   "metadata": {},
   "source": [
    "## Step 7: Concept of Perplexity and how it measures the model's performance in language modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f7640c-963b-4f4b-9b58-2498d17ecb2b",
   "metadata": {},
   "source": [
    "Perplexity measures how well a language model can predict the next word in a sequence, given the previous words. The lower the perplexity, the better the model is at predicting the next word. \n",
    "\n",
    "The perplexity of a language model on a test set is a function of the \n",
    "probability that the language model assigns to the test\n",
    "set.\n",
    "\n",
    "For a given test set w1, w2 · · · wN, perplexity (PP) is the \n",
    "probability of the test set, normalized by the number of words\n",
    "\n",
    "* The following formula can be used to calculate perplexity<b>: PPL = 2^(-log2(likelihood</b>)).\n",
    "\n",
    "Minimizing perplexity is the same as maximizing probability.\n",
    "Perplexity is a useful metric for comparing different language models, as it is a normalized measure of cross-entropy. This means that perplexity can be compared between models with different vocabularies or trained on different datasets"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
